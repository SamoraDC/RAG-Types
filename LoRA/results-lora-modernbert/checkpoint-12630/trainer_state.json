{
  "best_global_step": 12630,
  "best_metric": 0.2698032855987549,
  "best_model_checkpoint": "./results-lora-modernbert\\checkpoint-12630",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 12630,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 151882176.0,
      "learning_rate": 9.604117181314331e-05,
      "loss": 114956.992,
      "step": 500
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 206490928.0,
      "learning_rate": 9.208234362628662e-05,
      "loss": 42506.324,
      "step": 1000
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 11.937994956970215,
      "learning_rate": 8.812351543942994e-05,
      "loss": 13041.866,
      "step": 1500
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 14.79910659790039,
      "learning_rate": 8.416468725257324e-05,
      "loss": 0.4135,
      "step": 2000
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 5.911065101623535,
      "learning_rate": 8.020585906571655e-05,
      "loss": 0.3266,
      "step": 2500
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 2.279093027114868,
      "learning_rate": 7.624703087885986e-05,
      "loss": 0.4049,
      "step": 3000
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 5.948554039001465,
      "learning_rate": 7.228820269200317e-05,
      "loss": 0.3182,
      "step": 3500
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 4.009576797485352,
      "learning_rate": 6.832937450514649e-05,
      "loss": 0.3174,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8841743119266054,
      "eval_loss": 0.28714436292648315,
      "eval_runtime": 96.7258,
      "eval_samples_per_second": 9.015,
      "eval_steps_per_second": 0.569,
      "step": 4210
    },
    {
      "epoch": 1.0688836104513064,
      "grad_norm": 4.242794990539551,
      "learning_rate": 6.43705463182898e-05,
      "loss": 4.4833,
      "step": 4500
    },
    {
      "epoch": 1.187648456057007,
      "grad_norm": 2.8895201683044434,
      "learning_rate": 6.0411718131433105e-05,
      "loss": 0.3328,
      "step": 5000
    },
    {
      "epoch": 1.3064133016627077,
      "grad_norm": 5.931816101074219,
      "learning_rate": 5.64528899445764e-05,
      "loss": 0.2866,
      "step": 5500
    },
    {
      "epoch": 1.4251781472684084,
      "grad_norm": 13.133076667785645,
      "learning_rate": 5.2494061757719716e-05,
      "loss": 1.0085,
      "step": 6000
    },
    {
      "epoch": 1.5439429928741093,
      "grad_norm": 6.780450344085693,
      "learning_rate": 4.8535233570863024e-05,
      "loss": 0.4474,
      "step": 6500
    },
    {
      "epoch": 1.66270783847981,
      "grad_norm": 2.6533992290496826,
      "learning_rate": 4.457640538400634e-05,
      "loss": 0.2836,
      "step": 7000
    },
    {
      "epoch": 1.7814726840855108,
      "grad_norm": 6.52140474319458,
      "learning_rate": 4.061757719714965e-05,
      "loss": 0.2681,
      "step": 7500
    },
    {
      "epoch": 1.9002375296912115,
      "grad_norm": 3.17334246635437,
      "learning_rate": 3.665874901029295e-05,
      "loss": 0.2689,
      "step": 8000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8956422018348624,
      "eval_loss": 0.2810434401035309,
      "eval_runtime": 88.6685,
      "eval_samples_per_second": 9.834,
      "eval_steps_per_second": 0.62,
      "step": 8420
    },
    {
      "epoch": 2.019002375296912,
      "grad_norm": 3.573660135269165,
      "learning_rate": 3.2699920823436266e-05,
      "loss": 0.4975,
      "step": 8500
    },
    {
      "epoch": 2.137767220902613,
      "grad_norm": 1.2691694498062134,
      "learning_rate": 2.8741092636579575e-05,
      "loss": 0.2615,
      "step": 9000
    },
    {
      "epoch": 2.2565320665083135,
      "grad_norm": 4.7340826988220215,
      "learning_rate": 2.4782264449722883e-05,
      "loss": 0.2532,
      "step": 9500
    },
    {
      "epoch": 2.375296912114014,
      "grad_norm": 2.9154250621795654,
      "learning_rate": 2.0823436262866192e-05,
      "loss": 0.5435,
      "step": 10000
    },
    {
      "epoch": 2.494061757719715,
      "grad_norm": 7.685707092285156,
      "learning_rate": 1.6864608076009504e-05,
      "loss": 0.3218,
      "step": 10500
    },
    {
      "epoch": 2.6128266033254155,
      "grad_norm": 11.328198432922363,
      "learning_rate": 1.2905779889152811e-05,
      "loss": 0.2933,
      "step": 11000
    },
    {
      "epoch": 2.731591448931116,
      "grad_norm": 5.007776260375977,
      "learning_rate": 8.94695170229612e-06,
      "loss": 0.6012,
      "step": 11500
    },
    {
      "epoch": 2.850356294536817,
      "grad_norm": 4.468153476715088,
      "learning_rate": 4.98812351543943e-06,
      "loss": 0.2558,
      "step": 12000
    },
    {
      "epoch": 2.969121140142518,
      "grad_norm": 4.850804805755615,
      "learning_rate": 1.0292953285827396e-06,
      "loss": 0.2748,
      "step": 12500
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8990825688073395,
      "eval_loss": 0.2698032855987549,
      "eval_runtime": 71.3773,
      "eval_samples_per_second": 12.217,
      "eval_steps_per_second": 0.771,
      "step": 12630
    }
  ],
  "logging_steps": 500,
  "max_steps": 12630,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3201997925053440.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
